{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II\n",
    "## Multi-layer neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "X, t = make_blobs(n_samples=[400,800,400], centers=[[0,0],[1,2],[2,3]], \n",
    "                  n_features=2, random_state=2019)\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "random.seed(2020)\n",
    "random.shuffle(indices)\n",
    "\n",
    "\n",
    "X_train = X[indices[:800],:]\n",
    "X_val = X[indices[800:1200],:]\n",
    "X_test = X[indices[1200:],:]\n",
    "\n",
    "t_train = t[indices[:800]]\n",
    "t_val = t[indices[800:1200]]\n",
    "t_test = t[indices[1200:]]\n",
    "\n",
    "\n",
    "t2_train = t_train == 1\n",
    "t2_train = t2_train.astype('int')\n",
    "t2_val = (t_val == 1).astype('int')\n",
    "t2_test = (t_test == 1).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s = scaler.transform(X_val)\n",
    "P = len(X_train_s)\n",
    "\n",
    "dim_hidden = 6 \n",
    "\n",
    "dim_in =  len(X_train_s[0])\n",
    "dim_out = len(set(t_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(X, b=1):\n",
    "    # Put bias in position 0\n",
    "    sh = X.shape\n",
    "    if len(sh) == 1:\n",
    "        #X is a vector\n",
    "        return np.concatenate([np.array([1]), X])\n",
    "    else:\n",
    "        # X is a matrix\n",
    "        m = sh[0]\n",
    "        bias = np.ones((m,1)) # Makes a m*1 matrix of 1-s\n",
    "        bias.fill(b)\n",
    "        return np.concatenate([bias, X], axis  = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 2: A Multi-layer neural network classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to train and test a classifier on (X, t). You could have put some parts of the code in the last step into a loop and run it through some iterations. But instead of copying code for every network we want to train, we will build a general Multi-layer neural network classfier as a class. This class will have some of the same structure as the classifiers we made for linear and logistic regression. The task consists mainly in copying in parts from what you did in step 1 into the template below. Remember to add the *self*- prefix where needed, and be careful in your use of variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "class MNNClassifier():\n",
    "    \"\"\"A multi-layer neural network with one hidden layer\"\"\"\n",
    "    \n",
    "    def __init__(self, eta=0.01, dim_hidden = 6):\n",
    "\n",
    "        self.eta = eta\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.weights1 = None\n",
    "        self.weights2 = None\n",
    "        \n",
    "        \n",
    "    def fit(self, X_train, t_train, epochs = 100):\n",
    "\n",
    "        dim_in =  len(X_train[0]) \n",
    "        dim_out = len(set(t_train))\n",
    "        self.weights1 = np.random.normal(0, 0.5, [dim_in, dim_hidden+1]) #(L+ 1)×M weights between the input and the hidden layer \n",
    "        self.weights2 = np.random.normal(0, 0.5, [dim_hidden+1, dim_out]) #(M + 1)×N between the hidden layer and the output.\n",
    "        self.weights1[:,0] = -1\n",
    "        self.weights2[:,0] = -1\n",
    " \n",
    "        \n",
    "        for e in range(epochs):\n",
    "            hidden_a, output_a = self.forward(X_train)\n",
    "\n",
    "       \n",
    "            one_hot = np.zeros((t_train.size, t_train.max()+1))\n",
    "            one_hot[np.arange(t_train.size),t_train] = 1\n",
    "\n",
    "      \n",
    "            delta_o = (1 - output_a) * (one_hot - output_a) \n",
    "            delta_h = hidden_a * (1 - hidden_a) * (delta_o@self.weights2.T)\n",
    "            self.weights2 += self.eta * hidden_a.T @ delta_o\n",
    "            self.weights1 += self.eta * X_train.T @ delta_h \n",
    "              \n",
    "\n",
    "                \n",
    "    def forward(self, X):\n",
    "    \n",
    "        hidden_activations = logistic(X @ self.weights1)\n",
    "        output_activations = logistic(hidden_activations @ self.weights2) \n",
    "        \n",
    "        return hidden_activations, output_activations\n",
    "\n",
    "    def predict(self, X_train):\n",
    "        pred_o = self.forward(X_train)[1]\n",
    "        one_hot_pred = np.zeros_like(pred_o)\n",
    "        one_hot_pred[np.arange(len(pred_o)), pred_o.argmax(1)] = 1\n",
    "\n",
    "        pred = np.arange(len(X_train))\n",
    "    \n",
    "        for i, e in enumerate(one_hot_pred):\n",
    "            a = np.where(e == 1)\n",
    "            pred[i] = a[0]\n",
    "            \n",
    "        return pred\n",
    "        \n",
    "    def accuracy(self, X_test, t_test):   \n",
    "        return  np.mean(X_test==t_test)\n",
    "        \n",
    "\n",
    "mnn = MNNClassifier(dim_hidden = 6)\n",
    "mnn.fit(X_train, t_train, epochs = 60)\n",
    "predicted = mnn.predict(X_val)\n",
    "print(\"Accuracy:\", mnn.accuracy(predicted, t_val))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
